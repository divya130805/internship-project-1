# ============================================================
#  PREDICTIVE ANALYSIS USING MACHINE LEARNING
#  Dataset: California Housing (from scikit-learn)
#  Author: ChatGPT (GPT-5)
# ============================================================

import pandas as pd
import numpy as np
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import joblib

# ------------------------------------------------------------
# STEP 1: LOAD DATASET
# ------------------------------------------------------------
print("ðŸ”¹ Loading California Housing dataset...")
data = fetch_california_housing(as_frame=True)
df = data.frame
df.rename(columns={'MedHouseVal': 'MedianHouseValue'}, inplace=True)

print("\nâœ… Dataset Loaded Successfully!")
print(df.head())

# ------------------------------------------------------------
# STEP 2: EXPLORATORY DATA ANALYSIS
# ------------------------------------------------------------
print("\nðŸ”¹ Dataset Info:")
print(df.info())

print("\nðŸ”¹ Statistical Summary:")
print(df.describe())

# Correlation matrix
corr = df.corr()
print("\nðŸ”¹ Correlation with Target (MedianHouseValue):")
print(corr['MedianHouseValue'].sort_values(ascending=False))

# ------------------------------------------------------------
# STEP 3: DATA PREPROCESSING
# ------------------------------------------------------------
X = df.drop(columns=['MedianHouseValue'])
y = df['MedianHouseValue']

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\nâœ… Data Preprocessing Completed.")

# ------------------------------------------------------------
# STEP 4: MODEL TRAINING
# ------------------------------------------------------------
print("\nðŸ”¹ Training Random Forest Regressor...")
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

print("âœ… Model Training Completed!")

# ------------------------------------------------------------
# STEP 5: MODEL EVALUATION
# ------------------------------------------------------------
y_pred = model.predict(X_test_scaled)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("\nðŸ”¹ Model Evaluation:")
print(f"RMSE (Root Mean Squared Error): {rmse:.4f}")
print(f"RÂ² Score: {r2:.4f}")

# ------------------------------------------------------------
# STEP 6: VISUALIZATION
# ------------------------------------------------------------
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel("Actual Median House Value")
plt.ylabel("Predicted Median House Value")
plt.title("Actual vs Predicted Values")
plt.grid(True)
plt.show()

# ------------------------------------------------------------
# STEP 7: SAVE MODEL AND SCALER
# ------------------------------------------------------------
joblib.dump(model, "house_price_model.joblib")
joblib.dump(scaler, "scaler.joblib")
print("\nâœ… Model and Scaler saved successfully!")

# ------------------------------------------------------------
# STEP 8: SAMPLE PREDICTION
# ------------------------------------------------------------
print("\nðŸ”¹ Making a sample prediction...")

# Take a random sample from test data
sample = X_test.sample(1, random_state=1)
scaled_sample = scaler.transform(sample)
predicted_value = model.predict(scaled_sample)[0]

print("\nInput Features:")
print(sample)
print(f"\nðŸŽ¯ Predicted Median House Value: {predicted_value:.3f}")

print("\nðŸš€ Predictive Analysis Completed Successfully!")
